import asyncio
import httpx
import os
import logging
from typing import List, Dict, Any, Union
from datetime import datetime
from urllib.parse import urlparse, parse_qs
from http.server import BaseHTTPRequestHandler, HTTPServer
import socket
import threading
import uuid
import time
import json

from dotenv import load_dotenv
from mcp.server.fastmcp import FastMCP

# å¯¼å…¥æ’ä»¶æ¨¡å—
from providers import virustotal, local_whois, rdap, crtsh, fingerprint, portscan, otx, ipinfo, icp, abuseipdb, fofa, threatfox, ssl_info
from providers.base import format_result, validate_ip_address, validate_domain_name
from utils.cache import TTLCache
from config import CACHE_ENABLED, CACHE_TTL

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–ç¼“å­˜
global_cache = TTLCache(default_ttl=CACHE_TTL) if CACHE_ENABLED else None
if CACHE_ENABLED:
    logger.info(f"æœ¬åœ°ç¼“å­˜å·²å¯ç”¨ (TTL: {CACHE_TTL}s)")

# åˆå§‹åŒ– Server
mcp = FastMCP("CTI-Aggregator")


def _defang_ioc(text: str) -> str:
    """
    å¯¹ IOC (IP/Domain/URL) è¿›è¡Œå»æ¯’å¤„ç†ï¼Œé˜²æ­¢è¯¯ç‚¹å‡»ã€‚
    Example: 1.1.1.1 -> 1.1.1[.]1, http://bad.com -> hxxp://bad[.]com
    """
    if not text:
        return ""
    # æ›¿æ¢ http/https
    text = text.replace("http://", "hxxp://").replace("https://", "hxxps://")
    # æ›¿æ¢ç‚¹ . -> [.] (å¯é€‰ï¼Œç›®å‰ä»…æ›¿æ¢åè®®å¤´)
    return text

def _format_timestamp(ts: Any) -> str:
    """å°†Unixæ—¶é—´æˆ³è½¬æ¢ä¸ºå¯è¯»çš„æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²"""
    if not isinstance(ts, (int, float)):
        return str(ts)
    try:
        return datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')
    except (ValueError, TypeError):
        return str(ts)

def _coerce_unix_timestamp(value: Any) -> float:
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str):
        try:
            return float(value)
        except ValueError:
            return 0.0
    return 0.0


async def execute_provider_queries(client: httpx.AsyncClient, target: str,
                                 query_type: str = "ip") -> List[Dict[str, Any]]:
    """
    æ‰§è¡Œæ‰€æœ‰æä¾›å•†çš„æŸ¥è¯¢ä»»åŠ¡ã€‚
    """
    tasks = []

    # ä¸ºæ¯ä¸ªæä¾›å•†åˆ›å»ºæŸ¥è¯¢ä»»åŠ¡
    for provider in [virustotal, local_whois, rdap, crtsh, fingerprint, portscan, otx, ipinfo, icp, abuseipdb, fofa, threatfox, ssl_info]:
        try:
            if query_type == "ip" and hasattr(provider, 'query_ip'):
                tasks.append(provider.query_ip(client, target))
            elif query_type == "domain" and hasattr(provider, 'query_domain'):
                tasks.append(provider.query_domain(client, target))
        except Exception as e:
            logger.error(f"åˆ›å»º {provider.__name__} ä»»åŠ¡å¤±è´¥: {e}")

    if not tasks:
        return []

    results = await asyncio.gather(*tasks, return_exceptions=True)

    processed_results = []
    for result in results:
        if isinstance(result, Exception):
            logger.error(f"æŸ¥è¯¢ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {result}", exc_info=True)
            provider_name = "Unknown"
            if hasattr(result, '__traceback__'):
                tb_info = repr(result.__traceback__)
                if 'virustotal' in tb_info:
                    provider_name = 'VirusTotal'
                elif 'threatminer' in tb_info:
                    provider_name = 'ThreatMiner'
            processed_results.append(format_result(provider_name, error=str(result)))
        else:
            processed_results.append(result)

    return processed_results


def generate_report(target: str, results: List[Dict[str, Any]], report_type: str = "ip") -> str:
    """
    ç”Ÿæˆå›ºå®šæ ¼å¼çš„å¨èƒæƒ…æŠ¥æŠ¥å‘Šï¼Œé‡‡ç”¨åˆ†é˜¶æ®µä¸šåŠ¡æµç»“æ„ (Step 1-4)ã€‚
    """
    # 1. è§£ææ•°æ®
    data_map = {}
    for res in results:
        source = res.get("source", "Unknown")
        if res.get("status") == "success":
            data_map[source] = res.get("data", {})
    
    # æå–å…³é”®æ•°æ®æº
    vt_data = data_map.get("VirusTotal", {})
    abuse_data = data_map.get("AbuseIPDB", {})
    ipinfo_data = data_map.get("IPInfo", {})
    icp_data = data_map.get("ICP Filing", {}).get("results", [])
    shodan_data = data_map.get("PortScan", {})
    fofa_data = data_map.get("FOFA", {})
    rdap_data = data_map.get("RDAP", {}) or data_map.get("LocalWhois", {})
    # è¡¥å…… VT çš„ WHOIS ä¿¡æ¯ä½œä¸º fallback
    if not rdap_data and vt_data:
        rdap_data = {
            "registrar": vt_data.get("registrar"),
            "creation_date": vt_data.get("creation_date"),
            "whois_preview": vt_data.get("whois_preview")
        }
    fp_data = data_map.get("WebFingerprint", {})
    crt_data = data_map.get("crt.sh", {})
    otx_data = data_map.get("AlienVault OTX", {})
    threatfox_data = data_map.get("ThreatFox", {})
    ssl_jarm_data = data_map.get("SSL/JARM", {})

    # --- æŠ¥å‘Šå¼€å§‹ ---
    title_icon = "ğŸŒ" if report_type == "domain" else "ğŸ›¡ï¸"
    report = [f"# {title_icon} å¨èƒæƒ…æŠ¥åˆ†ææŠ¥å‘Š: {target}", ""]
    
    # --- ğŸš¨ 0. æ ¸å¿ƒé¢„è­¦ (Executive Summary) ---
    # æå–é«˜å±ç‰¹å¾
    apt_groups = otx_data.get("apt_groups", [])
    is_high_risk = False
    if vt_data and vt_data.get('malicious', 0) > 3:
        is_high_risk = True
        
    findings = []
    if apt_groups:
        findings.append(f"âš ï¸ ç–‘ä¼¼ APT ç»„ç»‡å…³è”: {', '.join(apt_groups)}")
    if is_high_risk:
        findings.append(f"âš ï¸ é«˜æ¶æ„è¯„åˆ† (VT: {vt_data.get('malicious')})")
    if threatfox_data.get("count", 0) > 0:
        findings.append(f"âš ï¸ ThreatFox å‘ç° {threatfox_data.get('count')} æ¡ IOC è®°å½•")
        
    if findings:
        report.append("## ğŸš¨ 0. æ ¸å¿ƒé¢„è­¦ (Executive Summary)")
        for f in findings:
            report.append(f"- {f}")
        report.append("")
    
    # --- Step 1: è§£æé˜¶æ®µ (Resolution) ---
    report.append("## 1ï¸âƒ£ Step 1: è§£æé˜¶æ®µ (Resolution)")
    report.append("> ç›®æ ‡ DNS è§£æã€å†å²è§£æè®°å½•ä¸è¢«åŠ¨ DNS å…³è”ã€‚")
    report.append("")
    
    # 1.1 å½“å‰è§£æ
    cur_v4 = []
    cur_v6 = []
    try:
        infos = socket.getaddrinfo(target, None)
        for _, _, _, _, addr in infos:
            ip = addr[0]
            if ":" in ip:
                if ip not in cur_v6: cur_v6.append(ip)
            else:
                if ip not in cur_v4: cur_v4.append(ip)
    except Exception:
        pass

    if report_type == "domain":
        v4_str = ", ".join(cur_v4[:10]) if cur_v4 else "`æ— `"
        v6_str = ", ".join(cur_v6[:10]) if cur_v6 else "`æ— `"
        report.append(f"- **å½“å‰ DNS è§£æ**:")
        report.append(f"  - IPv4: {v4_str}")
        report.append(f"  - IPv6: {v6_str}")
    elif report_type == "ip":
        report.append(f"- **IP åœ°å€**: `{target}`")
        # å°è¯•åå‘è§£æ
        try:
            hostname = socket.gethostbyaddr(target)[0]
            report.append(f"- **PTR åå‘è§£æ**: `{hostname}`")
        except:
            report.append(f"- **PTR åå‘è§£æ**: `æ— `")

    # 1.2 å†å²/å…³è”è§£æ (VT)
    if report_type == "domain":
        resolved_ips = vt_data.get("resolved_ips", [])
        hist_ips = [ip.get('ip', ip) if isinstance(ip, dict) else ip for ip in resolved_ips] if resolved_ips else []
        if hist_ips:
            report.append(f"- **å†å²è§£æ (VT)**: {', '.join(hist_ips[:10])}")
        else:
            report.append(f"- **å†å²è§£æ (VT)**: `æš‚æ— æ•°æ®`")
    elif report_type == "ip":
        resolutions = vt_data.get("resolutions", [])
        if resolutions:
            report.append(f"- **è¢«åŠ¨ DNS (å…³è”åŸŸå)**:")
            for r in resolutions[:5]:
                report.append(f"  - {r.get('last_resolved', '').split()[0]}: `{_defang_ioc(r.get('host_name'))}`")
        else:
            report.append(f"- **è¢«åŠ¨ DNS**: `æš‚æ— æ•°æ®`")
    report.append("")

    # --- Step 2: å±æ€§é˜¶æ®µ (Attributes) ---
    report.append("## 2ï¸âƒ£ Step 2: å±æ€§é˜¶æ®µ (Attributes)")
    report.append("> ç›®æ ‡çš„åŸºç¡€å±æ€§ã€å½’å±åœ°ã€æ³¨å†Œä¿¡æ¯ä¸å¤‡æ¡ˆæƒ…å†µã€‚")
    report.append("")

    # 2.1 å½’å±åœ°ä¸ç½‘ç»œ (IP Only)
    if report_type == "ip" or (report_type == "domain" and cur_v4):
        # å¦‚æœæ˜¯åŸŸåï¼Œå°è¯•ç”¨ç¬¬ä¸€ä¸ª IP å±•ç¤ºå½’å±åœ° (ä¸å¤Ÿå‡†ç¡®ï¼Œä½†æœ‰å‚è€ƒä»·å€¼)
        # è¿™é‡Œä¸»è¦å±•ç¤º IP æŠ¥å‘Šçš„å½’å±åœ°
        if report_type == "ip":
            city = ipinfo_data.get("city", "N/A")
            country = ipinfo_data.get("country", "N/A")
            org = ipinfo_data.get("org", "N/A")
            report.append(f"- **åœ°ç†ä½ç½®**: {city}, {country}")
            report.append(f"- **ASN / ISP**: {org}")

    # 2.2 ICP å¤‡æ¡ˆ (Domain Only)
    if report_type == "domain":
        if icp_data:
            icp_info = icp_data[0]
            report.append(f"- **ICP å¤‡æ¡ˆ**: {icp_info.get('entity_name', 'N/A')} ({icp_info.get('entity_type', 'N/A')}) - {icp_info.get('license', 'N/A')}")
        else:
            report.append(f"- **ICP å¤‡æ¡ˆ**: `æœªå¤‡æ¡ˆ`")

    # 2.3 WHOIS ä¿¡æ¯
    if rdap_data:
        registrar = rdap_data.get('registrar') or '`æš‚æ— æ•°æ®`'
        org_name = rdap_data.get('org') or vt_data.get('whois_preview', '').split('OrgName:')[-1].split('\\n')[0].strip() or '`æš‚æ— æ•°æ®`'
        report.append(f"- **æ³¨å†Œå•†**: {registrar}")
        report.append(f"- **æ³¨å†Œç»„ç»‡**: {org_name}")
        
        dates = []
        if rdap_data.get("creation_date"): dates.append(f"åˆ›å»º: {rdap_data.get('creation_date')}")
        if rdap_data.get("expiration_date"): dates.append(f"è¿‡æœŸ: {rdap_data.get('expiration_date')}")
        if dates:
            report.append(f"- **å…³é”®æ—¶é—´**: {'; '.join(dates)}")
        
        emails = rdap_data.get("emails", [])
        if emails:
            email_str = ", ".join(emails) if isinstance(emails, list) else str(emails)
            report.append(f"- **è”ç³»é‚®ç®±**: {email_str}")
    else:
        report.append("- **WHOIS**: `æš‚æ— è¯¦ç»†ä¿¡æ¯`")
    report.append("")

    # --- Step 3: å¨èƒé˜¶æ®µ (Threat) ---
    report.append("## 3ï¸âƒ£ Step 3: å¨èƒé˜¶æ®µ (Threat)")
    report.append("> å¤šæºå¨èƒæƒ…æŠ¥èšåˆï¼ŒåŒ…æ‹¬ä¿¡èª‰è¯„åˆ†ã€æ¶æ„æ ·æœ¬å…³è”ä¸å®¶æ—æ ‡è®°ã€‚")
    report.append("")

    # 3.1 ä¿¡èª‰è¯„åˆ†
    if vt_data:
        malicious = vt_data.get('malicious', 0)
        total = malicious + vt_data.get('harmless', 0) + vt_data.get('suspicious', 0) + vt_data.get('undetected', 0)
        vt_score = f"{malicious}/{total}"
        vt_icon = "ğŸ”´" if malicious > 0 else "ğŸŸ¢"
    else:
        vt_score = "`æš‚æ— æ•°æ®`"
        vt_icon = "âšª"
    
    report.append(f"- **VirusTotal**: {vt_icon} {vt_score}")
    
    if report_type == "ip":
        abuse_score = f"{abuse_data.get('score')}%" if abuse_data.get('score') is not None else "`æš‚æ— æ•°æ®`"
        abuse_icon = "ğŸ”´" if abuse_data.get('score', 0) > 0 else "ğŸŸ¢"
        report.append(f"- **AbuseIPDB**: {abuse_icon} ç½®ä¿¡åº¦ {abuse_score}")

    # 3.2 å¨èƒæƒ…æŠ¥ (OTX / ThreatFox)
    pulses = otx_data.get("pulses", [])
    if pulses:
        report.append(f"- **OTX æƒ…æŠ¥**: å…³è” {len(pulses)} æ¡æƒ…æŠ¥")
        for p in pulses[:3]:
            report.append(f"  - {p.get('name')}")
            
    tf_count = threatfox_data.get("count")
    if isinstance(tf_count, int) and tf_count > 0:
        report.append(f"- **ThreatFox**: å…³è” {tf_count} æ¡ IOC")
        families = threatfox_data.get("malware_families") or []
        if families:
            report.append(f"  - æ¶‰åŠå®¶æ—: {', '.join(families)}")

    # 3.3 å…³è”æ ·æœ¬ (Communicating Files)
    samples = vt_data.get("communicating_files", []) or vt_data.get("related_samples", [])
    if samples:
        report.append(f"- **å…³è”æ ·æœ¬**: å‘ç° {len(samples)} ä¸ª")
        # Sort by date
        samples_with_ts = []
        for s in samples:
            ts = _coerce_unix_timestamp(s.get("date") or s.get("creation_date") or 0)
            samples_with_ts.append((ts, s))
        samples_with_ts.sort(key=lambda x: x[0], reverse=True)
        
        for ts, s in samples_with_ts[:3]:
            name = s.get("name") or "N/A"
            date_str = _format_timestamp(ts) if ts else "N/A"
            hv = s.get("md5") or s.get("sha256") or s.get("sha1") or "N/A"
            report.append(f"  - [{date_str}] `{hv}` ({name})")
    else:
        report.append(f"- **å…³è”æ ·æœ¬**: `æœªå‘ç°`")
    report.append("")

    # --- Step 4: èµ„äº§é˜¶æ®µ (Assets) ---
    report.append("## 4ï¸âƒ£ Step 4: èµ„äº§é˜¶æ®µ (Assets)")
    report.append("> æš´éœ²åœ¨äº’è”ç½‘ä¸Šçš„ç«¯å£ã€æœåŠ¡ã€ç«™ç‚¹æŒ‡çº¹ä¸æ•°å­—è¯ä¹¦ã€‚")
    report.append("")

    # 4.1 ç«¯å£ä¸æœåŠ¡
    open_ports = shodan_data.get("open_ports", [])
    fofa_assets = fofa_data.get("assets", [])
    
    if open_ports:
        report.append(f"### Shodan ({len(open_ports)} ç«¯å£)")
        for p in open_ports[:10]:
             report.append(f"- **{p.get('port')}**: {p.get('service', 'Unknown')} {p.get('product', '')} {p.get('version', '')}")
    
    if fofa_assets:
        report.append(f"### FOFA ({len(fofa_assets)} èµ„äº§)")
        for asset in fofa_assets[:5]:
            port = asset.get('port')
            proto = asset.get('protocol')
            title = asset.get('title', '').strip() or 'N/A'
            link = asset.get('link')
            report.append(f"- **{port}/{proto}**: [{title}]({link})")
    
    if not open_ports and not fofa_assets:
        report.append("- `æœªæ£€æµ‹åˆ°æ˜æ˜¾å¼€æ”¾ç«¯å£æˆ–æœåŠ¡`")

    # 4.2 Web æŒ‡çº¹
    if fp_data:
        report.append(f"### Web æŒ‡çº¹")
        headers = fp_data.get('headers', {})
        if headers:
            report.append(f"- **Server**: {headers.get('Server', 'N/A')}")
            report.append(f"- **Powered-By**: {headers.get('X-Powered-By', 'N/A')}")
        if fp_data.get("favicon"):
             report.append(f"- **Favicon**: Hash `{fp_data['favicon'].get('hash')}`")
    
    # 4.3 SSL è¯ä¹¦ä¸ JARM
    report.append(f"### ğŸ” SSL è¯ä¹¦ä¸åŠ å¯†")
    
    # å®æ—¶ SSL ä¿¡æ¯
    ssl_info = ssl_jarm_data.get("ssl", {})
    if ssl_info and ssl_info.get("valid"):
        subject = ssl_info.get("subject", {})
        issuer = ssl_info.get("issuer", {})
        cn = subject.get("commonName", "N/A")
        issuer_cn = issuer.get("commonName", "N/A")
        valid_to = ssl_info.get("notAfter", "N/A")
        
        report.append(f"- **è¯ä¹¦ä¸»ä½“**: `{cn}`")
        report.append(f"- **é¢å‘æœºæ„**: `{issuer_cn}`")
        report.append(f"- **æœ‰æ•ˆæœŸè‡³**: `{valid_to}`")
        
        sans = ssl_info.get("sans", [])
        if sans:
            sans_str = ", ".join(sans[:5]) + ("..." if len(sans) > 5 else "")
            report.append(f"- **SAN åŸŸå**: {sans_str}")
            
        fp = ssl_info.get("fingerprint_sha1")
        if fp:
            report.append(f"- **æŒ‡çº¹ (SHA1)**: `{fp}`")
    else:
        if ssl_info.get("error"):
            report.append(f"- **SSL æ¢æµ‹å¤±è´¥**: {ssl_info.get('error')}")

    # JARM æŒ‡çº¹
    jarm_info = ssl_jarm_data.get("jarm", {})
    if jarm_info:
        if jarm_info.get("status") == "success":
            report.append(f"- **JARM æŒ‡çº¹**: `{jarm_info.get('raw')}`")
        elif jarm_info.get("status") == "missing":
            report.append(f"- **JARM**: `æœªå®‰è£… jarm å·¥å…·`")
        else:
            report.append(f"- **JARM**: æ¢æµ‹å¤±è´¥ ({jarm_info.get('error')})")
    
    shodan_jarm = shodan_data.get("jarm_fingerprints", [])
    if shodan_jarm:
        report.append(f"- **Shodan JARM**: {', '.join(shodan_jarm[:3])}" + (" ..." if len(shodan_jarm) > 3 else ""))
    
    fofa_jarm_set = set()
    for a in fofa_data.get("assets", [])[:20]:
        j = a.get("jarm")
        if isinstance(j, str) and j:
            fofa_jarm_set.add(j)
    if fofa_jarm_set:
        fofa_jarm_list = list(fofa_jarm_set)
        report.append(f"- **FOFA JARM**: {', '.join(fofa_jarm_list[:3])}" + (" ..." if len(fofa_jarm_list) > 3 else ""))

    # 4.4 å†å²è¯ä¹¦ (crt.sh) - ä»…åŸŸåæ¨¡å¼
    if report_type == "domain":
        certs = crt_data if isinstance(crt_data, list) else crt_data.get("subdomains", [])
        if certs:
            report.append(f"#### ğŸ“œ è¯ä¹¦å†å² (crt.sh)")
            if isinstance(certs[0], dict):
                 for cert in certs[:3]:
                    issued = cert.get('issued_date', '').split('T')[0]
                    cn = cert.get('common_name', 'N/A')
                    report.append(f"- [{issued}] **{cn}**")
            else:
                 report.append(f"- {', '.join(certs[:5])}...")

    return "\n".join(report)


@mcp.tool()
async def investigate_ip(ip: str) -> str:
    """
    [å¤šæºèšåˆ] è°ƒæŸ¥ IP åœ°å€ã€‚
    æŸ¥è¯¢ VirusTotal ä¿¡èª‰ã€å…³è”æ ·æœ¬ã€Shodan/FOFA ç«¯å£ã€AlienVault OTX æƒ…æŠ¥ã€‚
    è¿”å› Markdown æ ¼å¼çš„èšåˆæŠ¥å‘Šã€‚
    """
    logger.info(f"å¼€å§‹è°ƒæŸ¥ IP åœ°å€: {ip}")
    
    # æ£€æŸ¥ç¼“å­˜
    if global_cache:
        cache_key = f"report_ip_{ip}"
        cached_report = await global_cache.get(cache_key)
        if cached_report:
            logger.info(f"å‘½ä¸­ç¼“å­˜: {ip}")
            return cached_report

    try:
        # å¢åŠ è¶…æ—¶æ—¶é—´ä»¥é€‚åº”å¤§é‡å…³è”æ•°æ®çš„æŸ¥è¯¢
        async with httpx.AsyncClient(timeout=60.0) as client:
            results = await execute_provider_queries(client, ip, "ip")
            report = generate_report(ip, results, "ip")
            
            # å†™å…¥ç¼“å­˜
            if global_cache:
                await global_cache.set(cache_key, report)
                
            logger.info(f"IP åœ°å€ {ip} è°ƒæŸ¥å®Œæˆ")
            return report
    except Exception as e:
        logger.error(f"è°ƒæŸ¥ IP åœ°å€ {ip} å¤±è´¥: {e}", exc_info=True)
        return f"# âŒ è°ƒæŸ¥å¤±è´¥\n\né”™è¯¯ä¿¡æ¯: {str(e)}"


@mcp.tool()
async def investigate_domain(domain: str) -> str:
    """
    [å¤šæºèšåˆ] è°ƒæŸ¥åŸŸåã€‚
    æ‰§è¡Œå››æ­¥åˆ†ææ³•ï¼š1.è§£æ(DNS/å†å²) -> 2.å±æ€§(Whois/å¤‡æ¡ˆ) -> 3.å¨èƒ(ä¿¡èª‰/æ ·æœ¬) -> 4.èµ„äº§(æŒ‡çº¹/è¯ä¹¦)ã€‚
    """
    logger.info(f"å¼€å§‹è°ƒæŸ¥åŸŸå: {domain}")
    
    # æ£€æŸ¥ç¼“å­˜
    if global_cache:
        cache_key = f"report_domain_{domain}"
        cached_report = await global_cache.get(cache_key)
        if cached_report:
            logger.info(f"å‘½ä¸­ç¼“å­˜: {domain}")
            return cached_report

    try:
        # å¢åŠ è¶…æ—¶æ—¶é—´ä»¥é€‚åº”å¤§é‡å…³è”æ•°æ®çš„æŸ¥è¯¢
        async with httpx.AsyncClient(timeout=60.0) as client:
            results = await execute_provider_queries(client, domain, "domain")
            vt_ips: List[str] = []
            try:
                for r in results:
                    if r.get("source") == "VirusTotal" and r.get("status") == "success":
                        data = r.get("data", {})
                        resolved = data.get("resolved_ips", [])
                        vt_ips = [ip.get("ip", ip) if isinstance(ip, dict) else ip for ip in resolved]
                        break
            except Exception:
                vt_ips = []
            if not vt_ips:
                try:
                    _, _, addr_list = socket.gethostbyname_ex(domain)
                    vt_ips = list(dict.fromkeys(addr_list))
                except Exception:
                    vt_ips = []
            if vt_ips:
                try:
                    ps = await portscan.query_ip(client, vt_ips[0])
                    results.append(ps)
                except Exception as e:
                    logger.warning(f"ç«¯å£æ‰«æå¤±è´¥: {e}")
            report = generate_report(domain, results, "domain")
            
            # å†™å…¥ç¼“å­˜
            if global_cache:
                await global_cache.set(cache_key, report)
                
            logger.info(f"åŸŸå {domain} è°ƒæŸ¥å®Œæˆ")
            return report
    except Exception as e:
        logger.error(f"è°ƒæŸ¥åŸŸå {domain} å¤±è´¥: {e}", exc_info=True)
        return f"# âŒ åŸŸåè°ƒæŸ¥å¤±è´¥\n\né”™è¯¯ä¿¡æ¯: {str(e)}"


@mcp.tool()
async def investigate_batch(targets: List[str]) -> str:
    """
    [æ‰¹é‡åˆ†æ] è‡ªåŠ¨è¯†åˆ« IP æˆ–åŸŸåå¹¶å¹¶è¡Œè°ƒæŸ¥ã€‚
    è¾“å…¥ç¤ºä¾‹: ["1.1.1.1", "baidu.com"] æˆ– "1.1.1.1, baidu.com" (å¦‚æœæ˜¯å­—ç¬¦ä¸²ä¼šè‡ªåŠ¨åˆ†å‰²)
    è¿”å›åˆå¹¶çš„ç®€æŠ¥å’Œè¯¦ç»†æŠ¥å‘Šé“¾æ¥ã€‚
    """
    # å¤„ç†å­—ç¬¦ä¸²è¾“å…¥ (å¦‚æœç”¨æˆ·ä¼ å…¥é€—å·åˆ†éš”å­—ç¬¦ä¸²)
    final_targets = []
    if isinstance(targets, str):
        # æ›¿æ¢ä¸­æ–‡é€—å·
        targets = targets.replace("ï¼Œ", ",")
        final_targets = [t.strip() for t in targets.split(",") if t.strip()]
    else:
        final_targets = targets

    if not final_targets:
        return "âŒ è¯·æä¾›è‡³å°‘ä¸€ä¸ª IP æˆ–åŸŸå"

    if len(final_targets) > 20:
        return "âš ï¸ æ‰¹é‡æŸ¥è¯¢é™åˆ¶æœ€å¤š 20 ä¸ªç›®æ ‡ï¼Œè¯·åˆ†æ‰¹è¿›è¡Œã€‚"

    logger.info(f"å¼€å§‹æ‰¹é‡è°ƒæŸ¥: {final_targets}")
    
    # å¹¶å‘æ§åˆ¶
    semaphore = asyncio.Semaphore(5) # æœ€å¤š5ä¸ªå¹¶å‘ç›®æ ‡
    
    async def limited_investigate(target: str):
        async with semaphore:
            async with httpx.AsyncClient(timeout=60.0) as client:
                query_type = "ip" if validate_ip_address(target) else "domain"
                if query_type == "domain" and not validate_domain_name(target):
                    return {"target": target, "error": "Invalid Format", "report": ""}
                
                results = await execute_provider_queries(client, target, query_type)
                report = generate_report(target, results, query_type)
                return {"target": target, "type": query_type, "results": results, "report": report}

    # æ‰§è¡Œä»»åŠ¡
    tasks = [limited_investigate(t) for t in final_targets]
    batch_results = await asyncio.gather(*tasks)

    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    summary_report = ["# ğŸ“Š Batch Analysis Summary", "", "| Target | Type | Risk Score (VT) | Key Findings |", "| :--- | :--- | :--- | :--- |"]
    
    detailed_reports = []

    for res in batch_results:
        target = res.get("target")
        if "error" in res:
            summary_report.append(f"| {target} | N/A | N/A | âŒ {res['error']} |")
            continue
            
        # æå–å…³é”®ä¿¡æ¯ç”¨äºæ±‡æ€»
        # ç®€å•çš„æå– VT åˆ†æ•°
        vt_score = "N/A"
        key_findings = []
        
        # è§£æ results æ¥è·å–æ‘˜è¦
        for r in res.get("results", []):
            if r.get("source") == "VirusTotal" and r.get("status") == "success":
                data = r.get("data", {})
                vt_score = f"{data.get('malicious', 0)}/{data.get('malicious', 0) + data.get('harmless', 0)}"
            
            if r.get("source") == "AbuseIPDB" and r.get("status") == "success":
                 score = r.get("data", {}).get("abuseConfidenceScore")
                 if score and score > 0:
                     key_findings.append(f"Abuse:{score}%")
            
            if r.get("source") == "PortScan (Shodan)" and r.get("status") == "success":
                 ports = r.get("data", {}).get("open_ports", [])
                 if ports:
                     key_findings.append(f"Ports:{len(ports)}")
        
        findings_str = ", ".join(key_findings) or "No critical findings"
        summary_report.append(f"| {target} | {res.get('type')} | {vt_score} | {findings_str} |")
        
        detailed_reports.append(res.get("report"))

    final_output = "\n".join(summary_report) + "\n\n---\n\n" + "\n\n---\n\n".join(detailed_reports)
    return final_output


@mcp.tool()
async def health_check() -> str:
    """
    æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€ï¼ŒåŒ…æ‹¬ç¯å¢ƒå˜é‡å’Œæä¾›å•†é…ç½®ã€‚
    """
    status = ["# ğŸ”§ ç³»ç»Ÿå¥åº·æ£€æŸ¥", "---"]
    vt_key = os.getenv("VT_API_KEY")
    if vt_key:
        status.append("- âœ… **VirusTotal APIå¯†é’¥**: å·²é…ç½®")
    else:
        status.append("- âš ï¸ **VirusTotal APIå¯†é’¥**: æœªé…ç½® (VirusTotalæŸ¥è¯¢å°†å—é™)")
    
    shodan_key = os.getenv("SHODAN_API_KEY")
    if shodan_key:
        status.append("- âœ… **Shodan APIå¯†é’¥**: å·²é…ç½® (ä½¿ç”¨å®Œæ•´ API)")
    else:
        status.append("- â„¹ï¸ **Shodan APIå¯†é’¥**: æœªé…ç½® (ä½¿ç”¨å…è´¹ InternetDB)")

    fofa_email = os.getenv("FOFA_EMAIL")
    fofa_key = os.getenv("FOFA_API_KEY")
    if fofa_email and fofa_key:
        status.append("- âœ… **FOFA APIé…ç½®**: å·²é…ç½®")
    else:
        status.append("- âš ï¸ **FOFA APIé…ç½®**: æœªé…ç½® (éœ€åŒæ—¶é…ç½® EMAIL å’Œ KEY)")

    status.append("\n### æ´»è·ƒæä¾›å•†")
    status.append("- âœ… VirusTotal")
    status.append("- âœ… LocalWhois")
    status.append("- âœ… RDAP (Registration Data)")
    status.append("- âœ… crt.sh (Certificate History)")
    status.append("- âœ… WebFingerprint (Headers/Favicon)")
    if shodan_key:
        status.append("- âœ… PortScan (Shodan API)")
    else:
        status.append("- âœ… PortScan (Shodan InternetDB)")
    status.append("- âœ… AlienVault OTX (Threat Intelligence)")
    status.append("- âœ… IPInfo (Geolocation & Privacy)")
    status.append("- âœ… ICP Filing (beianx.cn)")

    abuse_key = os.getenv("ABUSEIPDB_API_KEY")
    if abuse_key:
        status.append("- âœ… AbuseIPDB (Reputation & Reports)")
    else:
        status.append("- âš ï¸ AbuseIPDB (Not Configured)")

    if fofa_email and fofa_key:
        status.append("- âœ… FOFA (Cyberspace Search)")
    else:
        status.append("- âš ï¸ FOFA (Not Configured)")

    return "\n".join(status)


@mcp.tool()
async def resolve_domain_ips(domain: str) -> str:
    if not validate_domain_name(domain):
        return "âŒ è¾“å…¥åŸŸåæ— æ•ˆ"
    ipv4 = []
    ipv6 = []
    try:
        infos = socket.getaddrinfo(domain, None)
        for family, _, _, _, addr in infos:
            ip = addr[0]
            if ":" in ip:
                if ip not in ipv6:
                    ipv6.append(ip)
            else:
                if ip not in ipv4:
                    ipv4.append(ip)
    except Exception as e:
        return f"# ğŸŒ å½“å‰è§£æ IP: {domain}\n\n- IPv4: `æ— `\n- IPv6: `æ— `\n\né”™è¯¯: {str(e)}"
    ipv4_str = ", ".join(ipv4) if ipv4 else "`æ— `"
    ipv6_str = ", ".join(ipv6) if ipv6 else "`æ— `"
    return f"# ğŸŒ å½“å‰è§£æ IP: {domain}\n\n- IPv4: {ipv4_str}\n- IPv6: {ipv6_str}"


if __name__ == "__main__":
    web_mode = os.getenv("WEB_SERVER", "0") == "1"
    if web_mode:
        host = os.getenv("WEB_HOST", "127.0.0.1")
        port = int(os.getenv("WEB_PORT", "8000"))

        JOBS: Dict[str, Dict[str, Any]] = {}

        class WebHandler(BaseHTTPRequestHandler):
            def _send_html(self, content: str, status: int = 200):
                data = content.encode("utf-8")
                self.send_response(status)
                self.send_header("Content-Type", "text/html; charset=utf-8")
                self.send_header("Content-Length", str(len(data)))
                self.end_headers()
                self.wfile.write(data)
            
            def _send_json(self, obj: Any, status: int = 200):
                data = json.dumps(obj, ensure_ascii=False).encode("utf-8")
                self.send_response(status)
                self.send_header("Content-Type", "application/json; charset=utf-8")
                self.send_header("Content-Length", str(len(data)))
                self.end_headers()
                self.wfile.write(data)

            def do_GET(self):
                try:
                    url = urlparse(self.path)
                    if url.path == "/":
                         html = (
                             "<!doctype html><html><head><meta charset='utf-8'><title>MCP CTI</title>"
                            "<style>:root{--bg:#ffffff;--fg:#0f172a;--muted:#6b7280;--primary:#2563eb;--border:#e5e7eb;--card:#f8fafc;--success:#22c55e}@media(prefers-color-scheme:dark){:root{--bg:#0b1220;--fg:#e5e7eb;--muted:#94a3b8;--primary:#60a5fa;--border:#1f2937;--card:#0f172a;--success:#22c55e}}body{font-family:system-ui,Arial,sans-serif;background:var(--bg);color:var(--fg);margin:0}a{color:var(--primary)}.container{max-width:900px;margin:32px auto;padding:0 20px}.card{background:var(--card);border:1px solid var(--border);border-radius:12px;padding:20px}.row{display:flex;gap:12px;align-items:center;flex-wrap:wrap}.title{font-size:20px;margin:0 0 8px}.desc{color:var(--muted);margin:0 0 16px}.chips{display:flex;gap:8px;flex-wrap:wrap;margin:8px 0}.chip{border:1px solid var(--border);border-radius:999px;padding:6px 10px;font-size:14px;background:transparent;color:var(--fg);cursor:pointer}.chip:hover{border-color:var(--primary)}textarea{width:100%;min-height:140px;border:1px solid var(--border);border-radius:10px;padding:12px;background:var(--bg);color:var(--fg);font-family:ui-monospace,monospace;font-size:14px}button{border:none;border-radius:10px;padding:10px 14px;font-size:14px;cursor:pointer}button.primary{background:var(--primary);color:#fff}button.secondary{background:transparent;color:var(--fg);border:1px solid var(--border)}button:disabled{opacity:.6;cursor:not-allowed}.progress{width:100%;background:var(--border);border-radius:999px;overflow:hidden;height:12px}.bar{height:12px;background:var(--success);width:0%}.stage{font-size:14px;color:var(--muted);margin:8px 0}.toolbar{display:flex;gap:8px;margin:12px 0;flex-wrap:wrap}.result{margin-top:16px}.footer{color:var(--muted);font-size:12px;margin-top:8px}</style>"
                            "</head><body>"
                            "<div class='container'>"
                            "<div class='card'>"
                            "<h3 class='title'>MCP CTI æµè§ˆå™¨æŸ¥è¯¢</h3>"
                            "<p class='desc'>è‡ªåŠ¨è¯†åˆ«åŸŸå / IPï¼›æ”¯æŒæ‰¹é‡æ··åˆï¼ˆé€—å· / ç©ºæ ¼ / æ¢è¡Œåˆ†éš”ï¼‰ã€‚</p>"
                            "<div class='chips'>"
                            "<button class='chip' data-s='1.1.1.1'>1.1.1.1</button>"
                            "<button class='chip' data-s='www.yyward.com'>www.yyward.com</button>"
                            "<button class='chip' data-s='8.8.8.8, example.com'>8.8.8.8, example.com</button>"
                            "</div>"
                            "<textarea id='input' placeholder='è¾“å…¥å¤šä¸ªç›®æ ‡ï¼Œæ¯è¡Œä¸€ä¸ªæˆ–ç”¨é€—å· / ç©ºæ ¼åˆ†éš”'></textarea>"
                            "<div class='toolbar'>"
                            "<button id='start' class='primary'>å¼€å§‹æŸ¥è¯¢</button>"
                            "<button id='clear' class='secondary'>æ¸…ç©º</button>"
                            "<button id='dl-md' class='secondary' disabled>å¯¼å‡º Markdown</button>"
                            "<button id='dl-html' class='secondary' disabled>å¯¼å‡º HTML</button>"
                            "</div>"
                            "<div class='progress'><div id='bar' class='bar'></div></div>"
                            "<div id='stage' class='stage'></div>"
                            "<div id='result' class='result'></div>"
                            "<div class='footer'>API: /investigate_ip, /investigate_domain, /investigate_batch, /submit, /task_status, /task_result, /resolve</div>"
                            "</div>"
                            "</div>"
                            "<script src='https://cdn.jsdelivr.net/npm/marked/marked.min.js'></script>"
                            "<script>"
                            "const startBtn=document.getElementById('start');const clearBtn=document.getElementById('clear');const dlMd=document.getElementById('dl-md');const dlHtml=document.getElementById('dl-html');const input=document.getElementById('input');const bar=document.getElementById('bar');const stageEl=document.getElementById('stage');const resultEl=document.getElementById('result');const chips=document.querySelectorAll('.chip');let jobId=null;let lastReport='';"
                            "chips.forEach(c=>c.addEventListener('click',()=>{const s=c.getAttribute('data-s');if(!input.value.trim())input.value=s;else input.value+='\\n'+s;}));"
                            "function setProgress(p){bar.style.width=(p||0)+'%';}"
                            "function setStage(t){stageEl.textContent=t||'';}"
                            "function enableExport(en){dlMd.disabled=!en;dlHtml.disabled=!en;}"
                            "function setBusy(b){startBtn.disabled=b;clearBtn.disabled=b;}"
                            "clearBtn.onclick=()=>{if(startBtn.disabled)return;input.value='';resultEl.innerHTML='';setProgress(0);setStage('');enableExport(false);};"
                            "dlMd.onclick=()=>{const blob=new Blob([lastReport],{type:'text/markdown'});const a=document.createElement('a');a.href=URL.createObjectURL(blob);a.download='report.md';a.click();};"
                            "dlHtml.onclick=()=>{const html='<!doctype html><html><head><meta charset=\"utf-8\"><title>CTI Report</title><style>body{font-family:system-ui,Arial,sans-serif;margin:24px}h1,h2,h3{margin-top:1em}</style></head><body>'+marked.parse(lastReport)+'</body></html>';const blob=new Blob([html],{type:'text/html'});const a=document.createElement('a');a.href=URL.createObjectURL(blob);a.download='report.html';a.click();};"
                            "startBtn.onclick=async()=>{enableExport(false);resultEl.innerHTML='';setProgress(0);setStage('æäº¤ä»»åŠ¡ä¸­...');setBusy(true);const q=input.value.trim();if(!q){alert('è¯·è¾“å…¥å†…å®¹');setBusy(false);return;}const form=new URLSearchParams();form.set('q',q);const resp=await fetch('/submit',{method:'POST',headers:{'Content-Type':'application/x-www-form-urlencoded'},body:form.toString()});const data=await resp.json();jobId=data.job_id;setStage('å·²æäº¤ï¼Œå¼€å§‹æŸ¥è¯¢...');const poll=async()=>{const s=await fetch('/task_status?job_id='+jobId);const info=await s.json();setProgress(info.progress||0);setStage(info.stage||info.status);if(info.status==='done'){const r=await fetch('/task_result?job_id='+jobId);const txt=await r.text();lastReport=txt;resultEl.innerHTML=marked.parse(txt);enableExport(true);setBusy(false);window.scrollTo({top:document.body.scrollHeight,behavior:'smooth'});}else if(info.status==='error'){resultEl.textContent='ä»»åŠ¡å¤±è´¥';setBusy(false);}else{setTimeout(poll,900);} };poll();};"
                            "</script>"
                            "</body></html>"
                         )
                         self._send_html(html)
                         return

                    params = parse_qs(url.query)
                    if url.path == "/query":
                        q = (params.get("q", [""])[0] or "").strip()
                        if not q:
                            self._send_html("<h3>ç¼ºå°‘æŸ¥è¯¢å‚æ•°</h3>", 400)
                            return
                        raw = q.replace("ï¼Œ", ",")
                        tokens = []
                        for part in raw.replace("\n", " ").split(" "):
                            part = part.strip()
                            if not part:
                                continue
                            if "," in part:
                                tokens.extend([p.strip() for p in part.split(",") if p.strip()])
                            else:
                                tokens.append(part)
                        unique_targets = []
                        for t in tokens:
                            if t not in unique_targets:
                                unique_targets.append(t)

                        if len(unique_targets) > 1:
                            report = asyncio.run(investigate_batch(", ".join(unique_targets)))
                        else:
                            target = unique_targets[0]
                            if validate_ip_address(target):
                                report = asyncio.run(investigate_ip(target))
                            elif validate_domain_name(target):
                                report = asyncio.run(investigate_domain(target))
                            else:
                                self._send_html("<h3>è¾“å…¥æ ¼å¼ä¸æ­£ç¡®ï¼šè¯·æä¾›æœ‰æ•ˆçš„åŸŸåæˆ– IP</h3>", 400)
                                return
                        html = (
                            "<!doctype html><html><head><meta charset='utf-8'><title>æŸ¥è¯¢ç»“æœ</title>"
                            "<style>body{font-family:system-ui,Arial,sans-serif;margin:24px}a{color:#0366d6;text-decoration:none}pre{white-space:pre-wrap;background:#f6f8fa;padding:16px;border-radius:8px;border:1px solid #eaecef}</style>"
                            "</head><body>"
                            f"<p><a href='/'>è¿”å›</a></p>"
                            f"<div id='md'></div>"
                            "<script src='https://cdn.jsdelivr.net/npm/marked/marked.min.js'></script>"
                            "<script>document.getElementById('md').innerHTML=marked.parse(" + json.dumps(report) + ");</script>"
                            "</body></html>"
                        )
                        self._send_html(html)
                        return

                    if url.path == "/investigate_ip":
                        ip = (params.get("ip", [""])[0] or "").strip()
                        if not ip:
                            self._send_html("ç¼ºå°‘ ip å‚æ•°", 400)
                            return
                        report = asyncio.run(investigate_ip(ip))
                        self._send_html(f"<pre>{report}</pre>")
                        return

                    if url.path == "/investigate_domain":
                        domain = (params.get("domain", [""])[0] or "").strip()
                        if not domain:
                            self._send_html("ç¼ºå°‘ domain å‚æ•°", 400)
                            return
                        report = asyncio.run(investigate_domain(domain))
                        self._send_html(f"<pre>{report}</pre>")
                        return
                    
                    if url.path == "/resolve":
                        domain = (params.get("domain", [""])[0] or "").strip()
                        if not domain:
                            self._send_html("ç¼ºå°‘ domain å‚æ•°", 400)
                            return
                        report = asyncio.run(resolve_domain_ips(domain))
                        self._send_html(f"<pre>{report}</pre>")
                        return
                    
                    if url.path == "/investigate_batch":
                        targets = (params.get("targets", [""])[0] or "").strip()
                        if not targets:
                            self._send_html("ç¼ºå°‘ targets å‚æ•°", 400)
                            return
                        report = asyncio.run(investigate_batch(targets))
                        self._send_html(f"<pre>{report}</pre>")
                        return

                    if url.path == "/task_status":
                        job_id = (params.get("job_id", [""])[0] or "").strip()
                        if not job_id or job_id not in JOBS:
                            self._send_json({"error": "job not found"}, 404)
                            return
                        self._send_json({
                            "status": JOBS[job_id].get("status"),
                            "stage": JOBS[job_id].get("stage"),
                            "progress": JOBS[job_id].get("progress", 0)
                        })
                        return

                    if url.path == "/task_result":
                        job_id = (params.get("job_id", [""])[0] or "").strip()
                        if not job_id or job_id not in JOBS:
                            self._send_html("job not found", 404)
                            return
                        rep = JOBS[job_id].get("report", "")
                        self._send_html(rep if rep else "no report", 200)
                        return

                    self._send_html("Not Found", 404)
                except Exception as e:
                    logger.error(f"Web handler error: {e}", exc_info=True)
                    self._send_html("Internal Server Error", 500)
            
            def do_POST(self):
                try:
                    url = urlparse(self.path)
                    length = int(self.headers.get("Content-Length", "0"))
                    body = self.rfile.read(length).decode("utf-8") if length > 0 else ""
                    params = parse_qs(body)
                    if url.path == "/submit":
                        q = (params.get("q", [""])[0] or "").strip()
                        if not q:
                            self._send_json({"error": "missing q"}, 400)
                            return
                        raw = q.replace("ï¼Œ", ",")
                        tokens = []
                        for part in raw.replace("\n", " ").split(" "):
                            part = part.strip()
                            if not part:
                                continue
                            if "," in part:
                                tokens.extend([p.strip() for p in part.split(",") if p.strip()])
                            else:
                                tokens.append(part)
                        unique_targets = []
                        for t in tokens:
                            if t not in unique_targets:
                                unique_targets.append(t)
                        job_id = uuid.uuid4().hex
                        JOBS[job_id] = {"status": "queued", "stage": "queued", "progress": 0, "report": ""}
                        def run_job():
                            try:
                                JOBS[job_id]["status"] = "running"
                                JOBS[job_id]["stage"] = "è§£æå¹¶å‡†å¤‡æŸ¥è¯¢"
                                JOBS[job_id]["progress"] = 10
                                time.sleep(0.2)
                                JOBS[job_id]["stage"] = "æ‰§è¡ŒæŸ¥è¯¢"
                                JOBS[job_id]["progress"] = 40
                                if len(unique_targets) > 1:
                                    report = asyncio.run(investigate_batch(", ".join(unique_targets)))
                                else:
                                    target = unique_targets[0]
                                    if validate_ip_address(target):
                                        report = asyncio.run(investigate_ip(target))
                                    else:
                                        report = asyncio.run(investigate_domain(target))
                                JOBS[job_id]["stage"] = "ç”ŸæˆæŠ¥å‘Š"
                                JOBS[job_id]["progress"] = 80
                                time.sleep(0.2)
                                JOBS[job_id]["report"] = report
                                JOBS[job_id]["stage"] = "å®Œæˆ"
                                JOBS[job_id]["progress"] = 100
                                JOBS[job_id]["status"] = "done"
                            except Exception as e:
                                logger.error(f"Job {job_id} failed: {e}", exc_info=True)
                                JOBS[job_id]["status"] = "error"
                                JOBS[job_id]["stage"] = "error"
                                JOBS[job_id]["progress"] = 100
                        threading.Thread(target=run_job, daemon=True).start()
                        self._send_json({"job_id": job_id})
                        return
                    self._send_json({"error": "Not Found"}, 404)
                except Exception as e:
                    logger.error(f"Web handler POST error: {e}", exc_info=True)
                    self._send_json({"error": "Internal Server Error"}, 500)

        httpd = HTTPServer((host, port), WebHandler)
        logger.info(f"Web æœåŠ¡å™¨å·²å¯åŠ¨: http://{host}:{port}/")
        print(f"Preview URL: http://{host}:{port}/")
        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            pass
        finally:
            httpd.server_close()
    else:
        logger.info("å¯åŠ¨ CTI-Aggregator MCP æœåŠ¡å™¨")
        mcp.run()
